server_name: 0.0.0.0

# Model loading options
default_load_in_8bit: false
default_torch_dtype: float16

# UI Settings
ui_show_starter_tooltips: false
ui_inference_open_options_by_default: false
ui_chat_reminder_message: "Language models may produce inaccurate information about people, places, or facts. <br/>å› è¨“ç·´æˆæœ¬é™åˆ¶ï¼Œæ¨¡å‹ç›®å‰å°é•·ä¸²å°è©±çš„è¡¨ç¾ä¸æ˜¯å¾ˆå¥½ï¼Œåœ¨å¤šè¼ªå°è©±å¾Œå¯èƒ½æœƒé–‹å§‹å›æ‡‰é‡è¤‡çš„å…§å®¹ã€‚å¦‚æœå°å›æ‡‰ä¸æ»¿æ„ï¼Œå¯ä»¥å˜—è©¦æŒ‰ä¸‹ã€ŒRegenerate Responseã€ã€‚å°è©±ç´€éŒ„åªæœƒä¿å­˜åœ¨ç€è¦½å™¨ä¸­ï¼Œè‹¥æœ‰éœ€è¦è«‹è‡ªè¡Œå‚™ä»½ (å±•é–‹å·¦ä¸‹è§’ã€ŒRaw Dataã€æŸ¥çœ‹ç›¸é—œè³‡è¨Š)ã€‚ä¸‹æ–¹ \"Examples\" æœ‰ä¸€äº›è¨Šæ¯ç¯„æœ¬å¯ä»¥é¸æ“‡ã€‚"
ui_features:
  - chat
  - inference
  - tools

# UI Customization
ui_title: TWLM Demo
# ui_emoji: ğŸ¦™ğŸ›ï¸
ui_subtitle: 'Taiwanese Mandarin LLM Project: [https://github.com/zetavg/twlm](https://github.com/zetavg/twlm)'
# ui_show_sys_info: true

default_generation_config:
  temperature: 1
  top_k: 40
  top_p: 0.4
  num_beams: 3
  repetition_penalty: 2.4
  max_new_tokens: 800
default_generation_stop_sequence: '### Human:'

# Special Modes
demo_mode: true
# ui_dev_mode: true
